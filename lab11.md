# [](#header-1)IT道德与伦理

在过去2年中，AI的崛起已不可阻挡。大量资金被投入到AI初创企业中，许多老牌科技公司（包括亚马逊、微软以及Facebook等巨头）都已经开设新的研究实验室。可以毫不夸张地说，现在软件就意味着AI。有些人预测，AI即将带来巨变，其影响甚至超过互联网。

![这里写图片描述](http://p2.so.qhimgs1.com/bdr/_240_/t01a1cdffc20952368e.jpg)
随着IT的发展，不免出现许多伦理上的问题。

![这里写图片描述](http://cms-bucket.nosdn.127.net/db335e41519e4028b5c1b36ef11676c520170317095230.jpeg?imageView&thumbnail=550x0)
一个充满道德问题的领域就是职场。AI将帮助机器人从事更复杂的工作，并导致更多人类工人被取代。举例来说，中国富士康公司计划利用机器人取代6万名工人。福特在德国科隆的工厂也投入机器人，与人类工人协调工作。
在许多工厂，人类工人已经开始与机器人共同工作。有些人认为，这可能对人类的心理健康造成巨大影响
更重要的是，如果越来越多的自动化已经对就业造成巨大影响，这也会对人们的心理健康产生负面影响。生物伦理学家、奥巴马总统前医疗顾问伊齐基尔·伊曼纽尔（Ezekiel Emanuel）表示：“如果你思考下能让人们的生活变得有意义的东西，你会发现三件事：有意义的人际关系、强烈的兴趣以及有意义的工作。其中有意义的工作是定义某人生活的重要因素。在有些地区，当工厂关门时失去工作，可能导致自杀、药物滥用以及抑郁症危险的增加。”
结果，我们可能需要看到更多的伦理需求。麻省理工学院专供法律和道德的专家凯特·达灵（Kate Darling）认为：“公司正遵循市场激励机制，这不是坏事，但我们不能仅仅依赖于伦理道德来控制它。它有助于监管到位，我们已经在隐私以及新技术领域看到它的存在，我们需要找出应对的方法。”
达灵指出，许多大牌公司（比如谷歌）已经成立道德委员会，来监督AI的开发和部署。有人认为，这种机制应该被广泛采用。达灵说：“我们不想扼杀创新，但到达某种程度时，我们可能想要创造某种结构。”
到底谁能入选谷歌道德委员会以及它到底能做什么，这些细节还所知甚少。但在2016年9月份，Facebook、谷歌以及亚马逊成立了联合组织，目标是寻找应对AI带来的安全与隐私威胁的解决方案。OpenAI也是类似的组织，旨在开发和推广能够让所有人受益的开源AI。谷歌的诺维格说：“机器学习技术被公开研究，并通过开放出版物和开源代码传播非常重要，我们可以分享所有奖励。”
如果我们能够制定行业标准和道德标准，并全面了解AI存在的风险，然后建立以伦理学家、技术专家以及企业领导人为核心的监管机制非常重要。这是利用AI为人类谋福利的最佳方式。斯特兰说：“我们的工作是减少人们对科幻电影中机器人接管世界的担忧，更多关注技术如何能够被用于帮助人类思考和决策，而非完全取代它。”

![这里写图片描述](http://p0.so.qhimgs1.com/bdr/_240_/t018f8f6458fc049b04.jpg)